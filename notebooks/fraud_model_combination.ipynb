{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit card fraud detector combining Fraud Detector and SageMaker models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Investigate and process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by downloading and reading in the credit card fraud data set.\n",
    "The dataset has been collected and analysed during a research collaboration of Worldline and the Machine Learning Group (http://mlg.ulb.ac.be) of ULB (Université Libre de Bruxelles) on big data mining and fraud detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "wget https://fraud-detector-blog-assets.s3.amazonaws.com/creditcard.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "data = pd.read_csv('creditcard.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a peek at our data (we only show a subset of the columns in the table):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.columns)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class column corresponds to whether or not a transaction is fradulent. We see that the majority of data is non-fraudulent with only $492$ ($.173\\%$), check the Class column mean, of the data corresponding to fraudulent examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the mean and standard deviation of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data.hist(bins=50,figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good, columns 𝑉𝑖 have been normalized to have 0 mean and unit standard deviation as the result of a PCA. Now, lets change the data to be Amazon Fraud Detector compatible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', 'v1', 'v2', 'v3', 'v4', 'v5', 'v6', 'v7', 'v8', 'v9', 'v10', 'v11', 'v12', 'v13', 'v14', 'v15', 'v16', 'v17', 'v18', 'v19', 'v20', 'v21', 'v22', 'v23', 'v24', 'v25', 'v26', 'v27', 'v28', 'amount', 'class'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# to lowecase\n",
    "data.columns = map(str.lower, data.columns)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', 'va', 'vb', 'vc', 'vd', 've', 'vf', 'vg', 'vh', 'vi', 'vj', 'vk', 'vl', 'vm', 'vn', 'vo', 'vp', 'vq', 'vr', 'vs', 'vt', 'vu', 'vv', 'vw', 'vx', 'vy', 'vz', 'vaa', 'vab', 'amount', 'class'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def standardize_headers(x):\n",
    "    if any(char.isdigit() for char in x):\n",
    "        if int(x[1:]) > 26:\n",
    "            return 'va'+chr(int(x[1:])+70)\n",
    "        return 'v'+chr(int(x[1:])+96)\n",
    "    return x\n",
    "\n",
    "# mapping number to letter\n",
    "data.rename(columns=standardize_headers, inplace=True)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then change the timestamp and label column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timedelta', 'va', 'vb', 'vc', 'vd', 've', 'vf', 'vg', 'vh', 'vi', 'vj', 'vk', 'vl', 'vm', 'vn', 'vo', 'vp', 'vq', 'vr', 'vs', 'vt', 'vu', 'vv', 'vw', 'vx', 'vy', 'vz', 'vaa', 'vab', 'amount', 'class'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# rename to the Fraud Detector name conventions \n",
    "data.rename(columns={'time':'timedelta'}, inplace=True)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get epoch time for the initial dataset date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1596600133.898222\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "epoch = datetime.utcfromtimestamp(0)\n",
    "def unix_time_seconds(dt):\n",
    "    return (dt - epoch).total_seconds()\n",
    "\n",
    "# Lets pretend that the data is from 2 days ago and we can test at the end with todays date.\n",
    "start_dt = datetime.strptime('Aug 4 2020  12:00AM', '%b %d %Y %I:%M%p')\n",
    "start_dt = datetime.now()\n",
    "start_ep = unix_time_seconds(start_dt)\n",
    "print(start_ep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Translate the current timestamp format (increasing seconds) to ISO 8601 standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def to_datetime(x):\n",
    "    current_ep = start_ep + x\n",
    "    current_dt = time.strftime('%Y-%m-%dT%H:%M:%SZ', time.localtime(current_ep))\n",
    "    return current_dt\n",
    "\n",
    "# translate seconds delta to actual datetimes in ISO 8601\n",
    "data['EVENT_TIMESTAMP'] = data['EVENT_TIMESTAMP'].apply(to_datetime)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split our dataset to get some test samples. After will upload the data to S3 using boto3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1414"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msk = np.random.rand(len(data)) < 0.995\n",
    "test = data[~msk]\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploading the data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO # python3; python2: BytesIO \n",
    "import boto3\n",
    "\n",
    "bucket = 'sample-creditcard-dataset' # already created on S3\n",
    "csv_buffer = StringIO()\n",
    "data.to_csv(csv_buffer, index=False)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object(bucket, 'creditcard-fraud-detector-training.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploading the data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO # python3; python2: BytesIO \n",
    "import boto3\n",
    "\n",
    "bucket = 'sample-creditcard-dataset' # already created on S3\n",
    "csv_buffer = StringIO()\n",
    "test.to_csv(csv_buffer, index=False)\n",
    "s3_resource = boto3.resource('s3')\n",
    "s3_resource.Object(bucket, 'creditcard-fraud-detector-test.csv').put(Body=csv_buffer.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the datasets ready we need create the necesary entities for build and deploy the fraud detection model. This can be done within the Amazon Fraud Detector console or through the API as shown in the second jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing our model endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "# -- fraud detector client --\n",
    "client = boto3.client('frauddetector',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entity, Detector, Model, and File Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY_TYPE    = \"transaction\" #change to your entity\n",
    "EVENT_TYPE     = \"testevent2\" #change to your envent_type\n",
    "\n",
    "DETECTOR_NAME = \"model_ensemble\" #change to your detector\n",
    "DETECTOR_VER  = \"1\"\n",
    "\n",
    "# -- name and version of model, used to get the model column names -- \n",
    "MODEL_NAME    = \"fraud_model\"\n",
    "MODEL_VER     = \"1\"\n",
    "\n",
    "record_count = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the test dataset from training columns and defining the start datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timedelta va vb vc vd ve vf vg vh vi vj vk vl vm vn vo vp vq vr vs vt vu vv vw vx vy vz vaa vab amount\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timedelta</th>\n",
       "      <th>va</th>\n",
       "      <th>vb</th>\n",
       "      <th>vc</th>\n",
       "      <th>vd</th>\n",
       "      <th>ve</th>\n",
       "      <th>vf</th>\n",
       "      <th>vg</th>\n",
       "      <th>vh</th>\n",
       "      <th>vi</th>\n",
       "      <th>vj</th>\n",
       "      <th>vk</th>\n",
       "      <th>vl</th>\n",
       "      <th>vm</th>\n",
       "      <th>vn</th>\n",
       "      <th>vo</th>\n",
       "      <th>vp</th>\n",
       "      <th>vq</th>\n",
       "      <th>vr</th>\n",
       "      <th>vs</th>\n",
       "      <th>vt</th>\n",
       "      <th>vu</th>\n",
       "      <th>vv</th>\n",
       "      <th>vw</th>\n",
       "      <th>vx</th>\n",
       "      <th>vy</th>\n",
       "      <th>vz</th>\n",
       "      <th>vaa</th>\n",
       "      <th>vab</th>\n",
       "      <th>amount</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>323.0</td>\n",
       "      <td>-0.704133</td>\n",
       "      <td>0.341397</td>\n",
       "      <td>1.740027</td>\n",
       "      <td>-1.661595</td>\n",
       "      <td>0.872313</td>\n",
       "      <td>-0.007311</td>\n",
       "      <td>0.923083</td>\n",
       "      <td>-0.575939</td>\n",
       "      <td>0.447697</td>\n",
       "      <td>0.264465</td>\n",
       "      <td>0.302329</td>\n",
       "      <td>-0.589641</td>\n",
       "      <td>-0.979096</td>\n",
       "      <td>-0.414870</td>\n",
       "      <td>0.227651</td>\n",
       "      <td>0.863539</td>\n",
       "      <td>-1.560955</td>\n",
       "      <td>0.570082</td>\n",
       "      <td>0.262597</td>\n",
       "      <td>0.018389</td>\n",
       "      <td>-0.206984</td>\n",
       "      <td>-0.321045</td>\n",
       "      <td>-0.334626</td>\n",
       "      <td>-0.813176</td>\n",
       "      <td>-0.265089</td>\n",
       "      <td>0.689043</td>\n",
       "      <td>-0.904113</td>\n",
       "      <td>-0.579831</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>363.0</td>\n",
       "      <td>-1.028699</td>\n",
       "      <td>0.910515</td>\n",
       "      <td>1.915180</td>\n",
       "      <td>2.469384</td>\n",
       "      <td>-0.008375</td>\n",
       "      <td>0.597584</td>\n",
       "      <td>0.251531</td>\n",
       "      <td>-0.331730</td>\n",
       "      <td>-0.095639</td>\n",
       "      <td>1.348750</td>\n",
       "      <td>-1.126126</td>\n",
       "      <td>-0.056429</td>\n",
       "      <td>1.141532</td>\n",
       "      <td>-0.984674</td>\n",
       "      <td>0.409776</td>\n",
       "      <td>0.291837</td>\n",
       "      <td>-0.648132</td>\n",
       "      <td>0.337319</td>\n",
       "      <td>0.242736</td>\n",
       "      <td>-0.186373</td>\n",
       "      <td>0.204878</td>\n",
       "      <td>0.948674</td>\n",
       "      <td>-0.014794</td>\n",
       "      <td>-0.064869</td>\n",
       "      <td>-0.882317</td>\n",
       "      <td>0.022126</td>\n",
       "      <td>-0.673108</td>\n",
       "      <td>0.085784</td>\n",
       "      <td>37.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>549.0</td>\n",
       "      <td>0.033854</td>\n",
       "      <td>-1.818313</td>\n",
       "      <td>1.077334</td>\n",
       "      <td>3.350537</td>\n",
       "      <td>-1.292195</td>\n",
       "      <td>1.546080</td>\n",
       "      <td>-0.282520</td>\n",
       "      <td>0.402055</td>\n",
       "      <td>0.928263</td>\n",
       "      <td>-0.011706</td>\n",
       "      <td>-1.801164</td>\n",
       "      <td>0.092265</td>\n",
       "      <td>-0.871234</td>\n",
       "      <td>-0.757440</td>\n",
       "      <td>-1.720001</td>\n",
       "      <td>-0.204210</td>\n",
       "      <td>0.428464</td>\n",
       "      <td>-0.689307</td>\n",
       "      <td>-0.677380</td>\n",
       "      <td>0.809245</td>\n",
       "      <td>0.108768</td>\n",
       "      <td>-0.451008</td>\n",
       "      <td>-0.475113</td>\n",
       "      <td>-0.261082</td>\n",
       "      <td>0.181753</td>\n",
       "      <td>0.025919</td>\n",
       "      <td>-0.019035</td>\n",
       "      <td>0.117564</td>\n",
       "      <td>530.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1172</th>\n",
       "      <td>914.0</td>\n",
       "      <td>-0.820178</td>\n",
       "      <td>1.225605</td>\n",
       "      <td>1.517290</td>\n",
       "      <td>-0.007492</td>\n",
       "      <td>0.310123</td>\n",
       "      <td>-0.936490</td>\n",
       "      <td>1.026234</td>\n",
       "      <td>-0.163058</td>\n",
       "      <td>-0.500997</td>\n",
       "      <td>-0.424367</td>\n",
       "      <td>-0.463979</td>\n",
       "      <td>0.220510</td>\n",
       "      <td>0.481360</td>\n",
       "      <td>0.021309</td>\n",
       "      <td>0.296479</td>\n",
       "      <td>0.193774</td>\n",
       "      <td>-0.703515</td>\n",
       "      <td>-0.168465</td>\n",
       "      <td>-0.955137</td>\n",
       "      <td>0.015005</td>\n",
       "      <td>0.032831</td>\n",
       "      <td>0.136686</td>\n",
       "      <td>-0.347711</td>\n",
       "      <td>0.390412</td>\n",
       "      <td>0.849821</td>\n",
       "      <td>-0.405567</td>\n",
       "      <td>0.074595</td>\n",
       "      <td>0.040960</td>\n",
       "      <td>11.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>947.0</td>\n",
       "      <td>1.130882</td>\n",
       "      <td>-0.306948</td>\n",
       "      <td>0.998749</td>\n",
       "      <td>0.225915</td>\n",
       "      <td>-0.544978</td>\n",
       "      <td>0.872664</td>\n",
       "      <td>-0.938950</td>\n",
       "      <td>0.372366</td>\n",
       "      <td>0.459415</td>\n",
       "      <td>-0.015577</td>\n",
       "      <td>0.839393</td>\n",
       "      <td>0.964977</td>\n",
       "      <td>0.923658</td>\n",
       "      <td>-0.166225</td>\n",
       "      <td>1.159326</td>\n",
       "      <td>0.983879</td>\n",
       "      <td>-1.002706</td>\n",
       "      <td>0.659583</td>\n",
       "      <td>-0.338309</td>\n",
       "      <td>0.024383</td>\n",
       "      <td>0.261644</td>\n",
       "      <td>0.792110</td>\n",
       "      <td>-0.145284</td>\n",
       "      <td>-0.763391</td>\n",
       "      <td>0.212113</td>\n",
       "      <td>0.638136</td>\n",
       "      <td>0.024789</td>\n",
       "      <td>0.013678</td>\n",
       "      <td>28.90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      timedelta        va        vb        vc        vd        ve        vf        vg        vh        vi        vj        vk        vl        vm        vn        vo        vp        vq        vr        vs        vt        vu        vv        vw        vx        vy        vz       vaa       vab  amount  class\n",
       "445       323.0 -0.704133  0.341397  1.740027 -1.661595  0.872313 -0.007311  0.923083 -0.575939  0.447697  0.264465  0.302329 -0.589641 -0.979096 -0.414870  0.227651  0.863539 -1.560955  0.570082  0.262597  0.018389 -0.206984 -0.321045 -0.334626 -0.813176 -0.265089  0.689043 -0.904113 -0.579831    0.77      0\n",
       "493       363.0 -1.028699  0.910515  1.915180  2.469384 -0.008375  0.597584  0.251531 -0.331730 -0.095639  1.348750 -1.126126 -0.056429  1.141532 -0.984674  0.409776  0.291837 -0.648132  0.337319  0.242736 -0.186373  0.204878  0.948674 -0.014794 -0.064869 -0.882317  0.022126 -0.673108  0.085784   37.92      0\n",
       "727       549.0  0.033854 -1.818313  1.077334  3.350537 -1.292195  1.546080 -0.282520  0.402055  0.928263 -0.011706 -1.801164  0.092265 -0.871234 -0.757440 -1.720001 -0.204210  0.428464 -0.689307 -0.677380  0.809245  0.108768 -0.451008 -0.475113 -0.261082  0.181753  0.025919 -0.019035  0.117564  530.85      0\n",
       "1172      914.0 -0.820178  1.225605  1.517290 -0.007492  0.310123 -0.936490  1.026234 -0.163058 -0.500997 -0.424367 -0.463979  0.220510  0.481360  0.021309  0.296479  0.193774 -0.703515 -0.168465 -0.955137  0.015005  0.032831  0.136686 -0.347711  0.390412  0.849821 -0.405567  0.074595  0.040960   11.03      0\n",
       "1228      947.0  1.130882 -0.306948  0.998749  0.225915 -0.544978  0.872664 -0.938950  0.372366  0.459415 -0.015577  0.839393  0.964977  0.923658 -0.166225  1.159326  0.983879 -1.002706  0.659583 -0.338309  0.024383  0.261644  0.792110 -0.145284 -0.763391  0.212113  0.638136  0.024789  0.013678   28.90      0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_variables = [column for column in test.columns if column not in  ['class']]\n",
    "dateTimeObj = datetime.strptime('Sep 3 2013  12:00AM', '%b %d %Y %I:%M%p')\n",
    "#dateTimeObj = datetime.now()\n",
    "timestampStr = dateTimeObj.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "print(' '.join(model_variables))\n",
    "cols = ['timedelta']\n",
    "#test[cols].applymap(np.int64)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timedelta': '46'}\n",
      "{'modelScores': [{'modelVersion': {'modelId': 'sagemaker_compatible', 'modelType': 'ONLINE_FRAUD_INSIGHTS', 'modelVersionNumber': '1.0'}, 'scores': {'sagemaker_compatible_insightscore': 155.0}}], 'ruleResults': [{'ruleId': 'low_fraud_risk', 'outcomes': ['allow_transaction']}], 'ResponseMetadata': {'RequestId': '0b886067-e493-460c-b043-8b9c89b5519e', 'HTTPStatusCode': 200, 'HTTPHeaders': {'content-type': 'application/x-amz-json-1.1', 'date': 'Wed, 05 Aug 2020 04:51:00 GMT', 'x-amzn-requestid': '0b886067-e493-460c-b043-8b9c89b5519e', 'content-length': '262', 'connection': 'keep-alive'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "import uuid \n",
    "\n",
    "# test the endpoint with a single prediction.\n",
    "eventId = uuid.uuid1()\n",
    "testrecord = test[model_variables].head(1).astype(str).to_dict(orient='records')[0]\n",
    "pred = client.get_event_prediction(detectorId=DETECTOR_NAME, \n",
    "                                       detectorVersionId=DETECTOR_VER,\n",
    "                                       eventId = str(eventId),\n",
    "                                       eventTypeName = EVENT_TYPE,\n",
    "                                       eventTimestamp = timestampStr, \n",
    "                                       entities = [{'entityType': ENTITY_TYPE, 'entityId':str(eventId.int)}],\n",
    "                                       eventVariables=  testrecord)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next block will use some parallelization to run several test against the fraud detector endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask \n",
    "from IPython.core.display import display, HTML\n",
    "from IPython.display import clear_output\n",
    "display(HTML(\"<style>.container { width:90% }</style>\"))\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "@dask.delayed\n",
    "def _predict(record):\n",
    "    eventId = uuid.uuid1()\n",
    "    try:\n",
    "        pred = client.get_event_prediction(detectorId=DETECTOR_NAME, \n",
    "                                       detectorVersionId=DETECTOR_VER,\n",
    "                                       eventId = str(eventId),\n",
    "                                       eventTypeName = EVENT_TYPE,\n",
    "                                       eventTimestamp = timestampStr, \n",
    "                                       entities = [{'entityType': ENTITY_TYPE, 'entityId':str(eventId.int)}],\n",
    "                                       eventVariables=  record) \n",
    "        \n",
    "        record[\"score\"]   = pred['modelScores'][0]['scores'][\"{0}_insightscore\".format(MODEL_NAME)]\n",
    "        record[\"outcomes\"]= pred['ruleResults'][0]['outcomes']\n",
    "        return record\n",
    "    \n",
    "    except:\n",
    "        pred  = client.get_event_prediction(detectorId=DETECTOR_NAME, \n",
    "                                       detectorVersionId='1',\n",
    "                                       eventId = str(eventId),\n",
    "                                       eventTypeName = EVENT_TYPE,\n",
    "                                       eventTimestamp = timestampStr, \n",
    "                                       entities = [{'entityType': ENTITY_TYPE, 'entityId':str(eventId.int)}],\n",
    "                                       eventVariables=  record) \n",
    "        record[\"score\"]   = \"-999\"\n",
    "        record[\"outcomes\"]= \"error\"\n",
    "        return record\n",
    "\n",
    "#just testing with 100 samples, increase the record_count variable o remove the .head to test the entire test dataset\n",
    "predict_data  = test[model_variables].head(record_count).astype(str).to_dict(orient='records')\n",
    "predict_score = []\n",
    "\n",
    "i=0\n",
    "for record in predict_data:\n",
    "    clear_output(wait=True)\n",
    "    rec = dask.delayed(_predict)(record)\n",
    "    predict_score.append(rec)\n",
    "    i += 1\n",
    "    print(\"current progress: \", round((i/record_count)*100,2), \"%\" )\n",
    "    \n",
    "predict_recs = dask.compute(*predict_score)\n",
    "\n",
    "# Calculate time taken and print results\n",
    "time_taken = time.time() - start\n",
    "tps = len(predict_recs) / time_taken\n",
    "\n",
    "print ('Process took %0.2f seconds' %time_taken)\n",
    "print ('Scored %d records' %len(predict_recs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame.from_dict(predict_recs, orient='columns')\n",
    "predictions.head(record_count)\n",
    "predictions.loc[predictions['score'] >=950, 'vaa':'outcomes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the model metrics on CloudWatch and the prediction history in Fraud Detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results to a csv file\n",
    "predictions.to_csv(MODEL_NAME + \"precictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.loc[data['vaa'] == 0.14205158164005, 'vaa':'EVENT_LABEL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('creditcard.csv', delimiter=',')\n",
    "\n",
    "feature_columns = df.columns[:-1]\n",
    "label_column = df.columns[-1]\n",
    "\n",
    "features = df[feature_columns].values.astype('float32')\n",
    "labels = (df[label_column].values).astype('float32')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, labels, test_size=0.1, random_state=42)\n",
    "\n",
    "payload = ','.join(map(str, X_train[0]))\n",
    "\n",
    "print(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "sagemaker_endpoint_name = 'fraud-detection-endpoint'\n",
    "sagemaker_runtime = boto3.client('sagemaker-runtime')\n",
    "response = sagemaker_runtime.invoke_endpoint(EndpointName=sagemaker_endpoint_name, ContentType='text/csv',\n",
    "                                                 Body=payload)\n",
    "print(response)\n",
    "pred_proba = json.loads(response['Body'].read().decode())\n",
    "formatted_float = \"{:.10f}\".format(pred_proba)\n",
    "prediction = 0 if pred_proba < 0.5 else 1\n",
    "# Note: XGBoost returns a float as a prediction, a linear learner would require different handling.\n",
    "print(\"classification pred_proba: {}, prediction: {}\".format(formatted_float, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finish"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
